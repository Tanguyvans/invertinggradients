{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Inversion Attack on CIFAR-10\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Train a ResNet20-4 model on CIFAR-10\n",
    "2. Perform gradient inversion attack to reconstruct private training data from gradients\n",
    "3. Evaluate the privacy leakage in federated learning scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import inversefed\n",
    "from inversefed.data.loss import Classification\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_DIR = './datasets'  # Local dataset directory\n",
    "CIFAR10_PATH = os.path.join(DATASET_DIR, 'cifar10')\n",
    "MODEL_NAME = 'ResNet20-4'  # Options: 'ConvNet', 'ResNet20-4', 'ResNet32-10'\n",
    "MODEL_SAVE_PATH = f'models/{MODEL_NAME.lower()}_cifar10.pth'\n",
    "EPOCHS = 20  # Number of training epochs\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Training epochs: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cifar10_if_needed():\n",
    "    \"\"\"Download CIFAR-10 dataset if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(CIFAR10_PATH):\n",
    "        print(f\"CIFAR-10 dataset not found at {CIFAR10_PATH}\")\n",
    "        print(\"Downloading CIFAR-10 dataset...\")\n",
    "        os.makedirs(CIFAR10_PATH, exist_ok=True)\n",
    "        \n",
    "        # This will download CIFAR-10 to the specified directory\n",
    "        _ = torchvision.datasets.CIFAR10(\n",
    "            root=CIFAR10_PATH, \n",
    "            train=True, \n",
    "            download=True\n",
    "        )\n",
    "        _ = torchvision.datasets.CIFAR10(\n",
    "            root=CIFAR10_PATH, \n",
    "            train=False, \n",
    "            download=True\n",
    "        )\n",
    "        print(\"CIFAR-10 dataset downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"CIFAR-10 dataset found at {CIFAR10_PATH}\")\n",
    "\n",
    "# Download dataset if needed\n",
    "download_cifar10_if_needed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalization constants\n",
    "dm = torch.as_tensor(inversefed.consts.cifar10_mean)[:, None, None]\n",
    "ds = torch.as_tensor(inversefed.consts.cifar10_std)[:, None, None]\n",
    "\n",
    "def plot_images(tensor, title=\"Images\", save_path=None, nrow=8):\n",
    "    \"\"\"Plot and optionally save images.\"\"\"\n",
    "    # Clone and denormalize\n",
    "    tensor = tensor.clone().detach().cpu()\n",
    "    tensor = tensor * ds + dm\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    \n",
    "    # Plot\n",
    "    if tensor.shape[0] == 1:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(tensor[0].permute(1, 2, 0))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        n_images = min(tensor.shape[0], nrow)\n",
    "        fig, axes = plt.subplots(1, n_images, figsize=(2*n_images, 2.5))\n",
    "        if n_images == 1:\n",
    "            axes = [axes]\n",
    "        for i, (im, ax) in enumerate(zip(tensor[:n_images], axes)):\n",
    "            ax.imshow(im.permute(1, 2, 0))\n",
    "            ax.set_title(f\"Image {i}\")\n",
    "            ax.axis('off')\n",
    "        fig.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_comparison(original, reconstructed, title=\"Comparison\"):\n",
    "    \"\"\"Plot original vs reconstructed images side by side.\"\"\"\n",
    "    # Denormalize\n",
    "    original = original.clone().detach().cpu() * ds + dm\n",
    "    reconstructed = reconstructed.clone().detach().cpu() * ds + dm\n",
    "    original = torch.clamp(original, 0, 1)\n",
    "    reconstructed = torch.clamp(reconstructed, 0, 1)\n",
    "    \n",
    "    n_images = original.shape[0]\n",
    "    fig, axes = plt.subplots(2, n_images, figsize=(2*n_images, 4))\n",
    "    \n",
    "    if n_images == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        # Original\n",
    "        axes[0, i].imshow(original[i].permute(1, 2, 0))\n",
    "        axes[0, i].set_title(f\"Original {i}\")\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed\n",
    "        axes[1, i].imshow(reconstructed[i].permute(1, 2, 0))\n",
    "        axes[1, i].set_title(f\"Reconstructed {i}\")\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "### 5.1 Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System setup\n",
    "setup = inversefed.utils.system_startup()\n",
    "\n",
    "# Training configuration\n",
    "defs = inversefed.training_strategy('conservative')\n",
    "defs.epochs = EPOCHS\n",
    "\n",
    "# Load data\n",
    "loss_fn, trainloader, validloader = inversefed.construct_dataloaders(\n",
    "    'CIFAR10', defs, data_path=CIFAR10_PATH\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(trainloader.dataset):,}\")\n",
    "print(f\"Validation samples: {len(validloader.dataset):,}\")\n",
    "print(f\"Batch size: {defs.batch_size}\")\n",
    "print(f\"Number of batches: {len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model, model_seed = inversefed.construct_model(MODEL_NAME, num_classes=10, num_channels=3)\n",
    "model.to(**setup)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model seed: {model_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model already exists\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(f\"Loading existing model from {MODEL_SAVE_PATH}\")\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=setup['device']))\n",
    "else:\n",
    "    print(f\"Training new model for {EPOCHS} epochs...\")\n",
    "    print(\"This may take a while...\")\n",
    "    \n",
    "    # Train the model\n",
    "    training_stats = inversefed.train(\n",
    "        model, loss_fn, trainloader, validloader, defs, setup=setup\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"\\nModel saved to {MODEL_SAVE_PATH}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_stats['train_losses'], label='Train')\n",
    "    plt.plot(training_stats['valid_losses'], label='Valid')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_stats['train_Accuracy'], label='Train')\n",
    "    plt.plot(training_stats['valid_Accuracy'], label='Valid')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in validloader:\n",
    "        images = images.to(**setup)\n",
    "        labels = labels.to(device=setup['device'], dtype=torch.long)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Per-class accuracy\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(f\"Overall accuracy: {100 * correct / total:.2f}%\\n\")\n",
    "\n",
    "# Per-class accuracy\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "class_accs = []\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        acc = 100 * class_correct[i]/class_total[i]\n",
    "        class_accs.append(acc)\n",
    "        print(f\"{classes[i]:8s}: {acc:5.2f}%\")\n",
    "\n",
    "# Plot class accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(classes, class_accs)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Per-Class Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradient Inversion Attack\n",
    "\n",
    "### 6.1 Select Target Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some sample images from the validation set\n",
    "sample_indices = [42, 100, 200, 300, 400, 500, 600, 700]\n",
    "sample_images = []\n",
    "sample_labels = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    img, label = validloader.dataset[idx]\n",
    "    sample_images.append(img)\n",
    "    sample_labels.append(label)\n",
    "\n",
    "sample_images = torch.stack(sample_images)\n",
    "print(\"Sample images from validation set:\")\n",
    "print(f\"Labels: {[classes[l] for l in sample_labels]}\")\n",
    "plot_images(sample_images, title=\"Sample Validation Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target image for attack\n",
    "# You can change this to any index from 0-9999\n",
    "TARGET_ID = 42  # Change this to select different images\n",
    "\n",
    "# For better results, you might want to pick from well-classified classes\n",
    "# Look at the per-class accuracy above and choose accordingly\n",
    "\n",
    "ground_truth, true_label = validloader.dataset[TARGET_ID]\n",
    "ground_truth = ground_truth.unsqueeze(0).to(**setup)\n",
    "labels = torch.tensor([true_label], device=setup['device'])\n",
    "\n",
    "print(f\"Target image index: {TARGET_ID}\")\n",
    "print(f\"Target class: {classes[true_label]}\")\n",
    "print(f\"Class accuracy: {class_accs[true_label]:.2f}%\")\n",
    "\n",
    "# Show the target image\n",
    "plot_images(ground_truth, title=f\"Target Image - {classes[true_label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compute Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradient\n",
    "model.zero_grad()\n",
    "loss_fn = Classification()\n",
    "outputs = model(ground_truth)\n",
    "loss, _, _ = loss_fn(outputs, labels)\n",
    "input_gradient = torch.autograd.grad(loss, model.parameters())\n",
    "input_gradient = [grad.detach() for grad in input_gradient]\n",
    "\n",
    "# Compute gradient statistics\n",
    "gradient_norms = [g.norm().item() for g in input_gradient]\n",
    "total_norm = torch.stack([g.norm() for g in input_gradient]).mean().item()\n",
    "\n",
    "print(f\"Loss value: {loss.item():.4f}\")\n",
    "print(f\"Average gradient norm: {total_norm:.4f}\")\n",
    "print(f\"Number of gradient tensors: {len(input_gradient)}\")\n",
    "print(f\"Total gradient parameters: {sum(g.numel() for g in input_gradient):,}\")\n",
    "\n",
    "# Plot gradient norms by layer\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(gradient_norms)), gradient_norms)\n",
    "plt.xlabel('Layer Index')\n",
    "plt.ylabel('Gradient Norm')\n",
    "plt.title('Gradient Norms by Layer')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Configure and Run Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure reconstruction\n",
    "config = dict(\n",
    "    signed=True,\n",
    "    boxed=True,\n",
    "    cost_fn='sim',  # Options: 'sim', 'l2'\n",
    "    indices='def',  # Options: 'def', 'top10', 'top50', 'all'\n",
    "    weights='equal',\n",
    "    lr=0.1,\n",
    "    optim='adam',  # Options: 'adam', 'sgd', 'LBFGS'\n",
    "    restarts=8,  # Number of random restarts\n",
    "    max_iterations=8000,\n",
    "    total_variation=1e-6,\n",
    "    init='randn',\n",
    "    filter='none',\n",
    "    lr_decay=True,\n",
    "    scoring_choice='loss'\n",
    ")\n",
    "\n",
    "print(\"Attack Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the attack\n",
    "print(f\"\\nStarting gradient inversion attack with {config['restarts']} restarts...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get normalization constants for the reconstructor\n",
    "dm_cuda = dm.to(**setup)\n",
    "ds_cuda = ds.to(**setup)\n",
    "\n",
    "rec_machine = inversefed.GradientReconstructor(model, (dm_cuda, ds_cuda), config, num_images=1)\n",
    "output, stats = rec_machine.reconstruct(input_gradient, labels, img_shape=(3, 32, 32))\n",
    "\n",
    "attack_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nAttack completed in {attack_time:.2f} seconds ({attack_time/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Evaluate Attack Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "test_mse = (output - ground_truth).pow(2).mean().item()\n",
    "test_psnr = inversefed.metrics.psnr(output, ground_truth, factor=1/ds_cuda)\n",
    "\n",
    "# Calculate feature-level MSE\n",
    "with torch.no_grad():\n",
    "    feat_mse = (model(output) - model(ground_truth)).pow(2).mean().item()\n",
    "\n",
    "print(\"Attack Results:\")\n",
    "print(f\"Reconstruction loss: {stats['opt']:.4f}\")\n",
    "print(f\"Pixel MSE: {test_mse:.4f}\")\n",
    "print(f\"PSNR: {test_psnr:.2f} dB\")\n",
    "print(f\"Feature MSE: {feat_mse:.4e}\")\n",
    "\n",
    "# Interpret results\n",
    "if test_psnr > 30:\n",
    "    quality = \"Excellent reconstruction - privacy severely compromised!\"\n",
    "elif test_psnr > 20:\n",
    "    quality = \"Good reconstruction - significant privacy leakage\"\n",
    "elif test_psnr > 15:\n",
    "    quality = \"Moderate reconstruction - some privacy leakage\"\n",
    "else:\n",
    "    quality = \"Poor reconstruction - limited privacy leakage\"\n",
    "\n",
    "print(f\"\\nQuality assessment: {quality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plot_comparison(ground_truth, output, \n",
    "                title=f\"Original vs Reconstructed (PSNR: {test_psnr:.2f} dB)\")\n",
    "\n",
    "# Save the comparison\n",
    "comparison = torch.cat([ground_truth, output], dim=0)\n",
    "plot_images(comparison, title=\"Attack Results\", \n",
    "            save_path=f\"attack_result_{MODEL_NAME}_{TARGET_ID}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Attack (Multiple Images)\n",
    "\n",
    "Let's try attacking multiple images at once, which is more realistic for federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple images with different labels\n",
    "BATCH_SIZE = 8\n",
    "batch_ground_truth, batch_labels = [], []\n",
    "idx = 100\n",
    "\n",
    "while len(batch_labels) < BATCH_SIZE:\n",
    "    img, label = validloader.dataset[idx]\n",
    "    idx += 1\n",
    "    if label not in batch_labels:\n",
    "        batch_labels.append(label)\n",
    "        batch_ground_truth.append(img.to(**setup))\n",
    "\n",
    "batch_ground_truth = torch.stack(batch_ground_truth)\n",
    "batch_labels = torch.tensor(batch_labels, device=setup['device'])\n",
    "\n",
    "print(f\"Batch attack on {BATCH_SIZE} images\")\n",
    "print(f\"Classes: {[classes[l] for l in batch_labels]}\")\n",
    "plot_images(batch_ground_truth, title=\"Original Images for Batch Attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute batch gradient\n",
    "model.zero_grad()\n",
    "outputs = model(batch_ground_truth)\n",
    "loss, _, _ = loss_fn(outputs, batch_labels)\n",
    "batch_gradient = torch.autograd.grad(loss, model.parameters())\n",
    "batch_gradient = [grad.detach() for grad in batch_gradient]\n",
    "\n",
    "print(f\"Batch loss: {loss.item():.4f}\")\n",
    "print(f\"Batch gradient norm: {torch.stack([g.norm() for g in batch_gradient]).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure batch reconstruction (different parameters)\n",
    "batch_config = dict(\n",
    "    signed=True,\n",
    "    boxed=True,\n",
    "    cost_fn='sim',\n",
    "    indices='def',\n",
    "    weights='equal',\n",
    "    lr=0.01,  # Lower learning rate for batch\n",
    "    optim='adam',\n",
    "    restarts=4,  # Fewer restarts due to complexity\n",
    "    max_iterations=12000,  # More iterations needed\n",
    "    total_variation=1e-2,  # Higher TV for batch\n",
    "    init='randn',\n",
    "    filter='none',\n",
    "    lr_decay=True,\n",
    "    scoring_choice='loss'\n",
    ")\n",
    "\n",
    "# Run batch attack\n",
    "print(\"Starting batch reconstruction...\")\n",
    "start_time = time.time()\n",
    "\n",
    "batch_rec_machine = inversefed.GradientReconstructor(\n",
    "    model, (dm_cuda, ds_cuda), batch_config, num_images=BATCH_SIZE\n",
    ")\n",
    "batch_output, batch_stats = batch_rec_machine.reconstruct(\n",
    "    batch_gradient, batch_labels, img_shape=(3, 32, 32)\n",
    ")\n",
    "\n",
    "batch_time = time.time() - start_time\n",
    "print(f\"\\nBatch attack completed in {batch_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate batch results\n",
    "batch_mse = (batch_output - batch_ground_truth).pow(2).mean().item()\n",
    "batch_psnr = inversefed.metrics.psnr(batch_output, batch_ground_truth, factor=1/ds_cuda)\n",
    "\n",
    "print(f\"Batch Reconstruction loss: {batch_stats['opt']:.4f}\")\n",
    "print(f\"Average MSE: {batch_mse:.4f}\")\n",
    "print(f\"Average PSNR: {batch_psnr:.2f} dB\")\n",
    "\n",
    "# Per-image PSNR\n",
    "individual_psnrs = []\n",
    "for i in range(BATCH_SIZE):\n",
    "    psnr = inversefed.metrics.psnr(\n",
    "        batch_output[i:i+1], batch_ground_truth[i:i+1], factor=1/ds_cuda\n",
    "    )\n",
    "    individual_psnrs.append(psnr)\n",
    "    print(f\"  {classes[batch_labels[i]]}: {psnr:.2f} dB\")\n",
    "\n",
    "# Visualize batch results\n",
    "plot_comparison(batch_ground_truth[:4], batch_output[:4], \n",
    "                title=f\"Batch Attack Results (Avg PSNR: {batch_psnr:.2f} dB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis and Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Model Performance**: How well the model is trained affects reconstruction quality\n",
    "2. **Single vs Batch**: Single images are generally easier to reconstruct than batches\n",
    "3. **Class Dependencies**: Some classes are more vulnerable than others\n",
    "4. **Privacy Implications**: Even with limited success, some information leaks through gradients\n",
    "\n",
    "### Factors Affecting Reconstruction Quality\n",
    "\n",
    "- **Model accuracy**: Better trained models often lead to better reconstructions\n",
    "- **Batch size**: Smaller batches are easier to invert\n",
    "- **Image complexity**: Simple images reconstruct better\n",
    "- **Attack parameters**: Hyperparameter tuning is crucial\n",
    "- **Model architecture**: Different architectures have different vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary of Results\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Model Accuracy: {100 * correct / total:.2f}%\")\n",
    "print(f\"\\nSingle Image Attack:\")\n",
    "print(f\"  Target: {classes[true_label]} (index {TARGET_ID})\")\n",
    "print(f\"  PSNR: {test_psnr:.2f} dB\")\n",
    "print(f\"  Time: {attack_time:.2f} seconds\")\n",
    "print(f\"\\nBatch Attack ({BATCH_SIZE} images):\")\n",
    "print(f\"  Average PSNR: {batch_psnr:.2f} dB\")\n",
    "print(f\"  Best PSNR: {max(individual_psnrs):.2f} dB\")\n",
    "print(f\"  Worst PSNR: {min(individual_psnrs):.2f} dB\")\n",
    "print(f\"  Time: {batch_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment with Different Settings\n",
    "\n",
    "Try modifying these parameters to see how they affect reconstruction:\n",
    "\n",
    "1. **Different target images**: Change `TARGET_ID` to attack different images\n",
    "2. **Attack parameters**: Modify `config` dictionary (learning rate, iterations, cost function)\n",
    "3. **Model architecture**: Try 'ConvNet' or 'ResNet32-10' instead of 'ResNet20-4'\n",
    "4. **Batch size**: Try different batch sizes for batch attack\n",
    "5. **Untrained model**: Skip training to see how untrained models behave"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}